}
set.seed(123)
X = data_gen(n = 100, true_p=40, p = 80)
# set parameters
nu1 = nu2 = nu3 = gamma_1 = gamma_2 = gamma_3 = 0.1
m = 5
phi = 0.5
# sparse.biADMM algorithm
res1 = sparse.biADMM(X, nu1, nu2, nu3, gamma_1, gamma_2, gamma_3, feature_weight = rep(1,ncol(X)),
m, phi, niter = 10, tol = 0.0001, output = 0)
??kernel_weights
?kernel_weights
require(cvxbiclustr)
set.seed(123)
X = data_gen(n = 100, true_p=40, p = 80)
# set parameters
nu1 = nu2 = nu3 = gamma_1 = gamma_2 = gamma_3 = 0.1
m = 5
phi = 0.5
# sparse.biADMM algorithm
res1 = sparse.biADMM(X, nu1, nu2, nu3, gamma_1, gamma_2, gamma_3, feature_weight = rep(1,ncol(X)),
m, phi, niter = 10, tol = 0.0001, output = 0)
res1 = sparse.biADMM(X, nu1, nu2, nu3, gamma_1, gamma_2, gamma_3, feature_weight = rep(1,ncol(X)),m, phi, niter = 10, tol = 0.0001, output = 0)
kernel_weights(X)
usethis::use_package(package = "cvxclustr", type = "Imports")
sparse.biADMM = function(X, nu1, nu2, nu3,
gamma_1, gamma_2, gamma_3,
feature_weight = rep(1,ncol(X)),
m = 5, phi=0.5,niter = 1000,tol = 0.1,output = 1){
require(reticulate)
require(cvxbiclustr)
require(cvxclustr)
require(Matrix)
require(MASS)
n <- dim(X)[1]; p <- dim(X)[2]
n2 <- n*(n-1)/2
p2 <- p*(p-1)/2
elks <- elk(n,p)
el1 <- elks$el1
el2 <- elks$el2
ek1 <- elks$ek1
ek2 <- elks$ek2
k_row <- m
k_col <- m
w_row <- cvxclustr::kernel_weights(t(X), phi)
w_col <- cvxclustr::kernel_weights(X, phi)
w_row <- cvxclustr::kernel_weights(w_row, k_row, n)
w_col <- cvxclustr::kernel_weights(w_col, k_col, p)
w_row <- w_row/sum(w_row)
w_col <- w_col/sum(w_col)
w_row <- w_row/sqrt(p)
w_col <- w_col/sqrt(n)
feature_weight <- feature_weight/ sum(feature_weight)/sqrt(n)
# row and column weight
w_l <- w_row; u_k <- w_col
A <- matrix(0,n,p)
v <- matrix(0,p,n2)
z <- matrix(0,n,p2)
g <- matrix(0,n,p)
lambda_1 <- matrix(0,p,n2)
lambda_2 <- matrix(0,n,p2)
lambda_3 <- matrix(0,n,p)
for(iter in 1: niter){
A_old <- A; v_old <- v; z_old <- z; g_old <- g;
lambda_1_old <- lambda_1; lambda_2_old <- lambda_2 ; lambda_3_old <- lambda_3
# update A
# En <- diag(0:(n - 1)) + diag((n - 1):0) - matrix(1, n, n) + diag(1, n, n)
# Ep <- diag(0:(p - 1)) + diag((p - 1):0) - matrix(1, p, p) + diag(1, p, p)
En <- diag(n,n) - matrix(1, n, n)
Ep <- diag(p,p) - matrix(1, p, p)
M <- diag(1,n,n) + nu1 * En
N <- nu2 * Ep + nu3 * diag(1,p)
lv <- lambda_1 + nu1 * v
lz <- lambda_2 + nu2 * z
lg <- lambda_3 + nu3 * g
C2 <- (el1-el2) %*% t(lv)
C3 <- lz %*% t(ek1-ek2)
C4 <- lg %*% diag(1,p)
C <- X +  C2 + C3 + C4
A <- sylvester(M,t(N),C)
al1 <- t(A) %*% el1
al2 <- t(A) %*% el2
ak1 <- A %*% ek1
ak2 <- A %*% ek2
# update v z g
sigma_1 <- gamma_1 * w_l/nu1
vtemp <- al1 - al2 - 1/nu1 * lambda_1
# get positive results
temp1 <- ifelse((1 - sigma_1/sqrt(apply(vtemp^2,2,sum))) < 0, 0,1 - sigma_1/sqrt(apply(vtemp^2,2,sum)))
temp2 <- matrix(temp1,dim(vtemp)[1],dim(vtemp)[2], byrow = TRUE) * vtemp
v <- temp2
ztemp <- ak1 - ak2 - 1/nu2 * lambda_2
sigma_2 <- gamma_2 * u_k/nu2
temp3 <- ifelse((1 - sigma_2/sqrt(apply(ztemp^2,2,sum))) < 0, 0,1 - sigma_2/sqrt(apply(ztemp^2,2,sum)))
temp4 <- matrix(temp3,dim(ztemp)[1],dim(ztemp)[2], byrow = TRUE) * ztemp
z <- temp4
gtemp <- A - 1/nu3 * lambda_3
sigma_3 <- gamma_3 * feature_weight/nu3
temp5 <- ifelse((1 - sigma_3/sqrt(apply(gtemp^2,2,sum))) < 0, 0,1 - sigma_3/sqrt(apply(gtemp^2,2,sum)))
temp6 <- matrix(temp5,dim(gtemp)[1],dim(gtemp)[2], byrow = TRUE) * gtemp
g <- temp6
# update lambda 1
lambda_1 <- lambda_1 + nu1 * (v - al1 + al2)
# update lambda 2
lambda_2 <- lambda_2 + nu2 * (z - ak1 + ak2)
# update lambda 3
lambda_3 <- lambda_3 + nu3 * (g - A)
if(output == 1){
print('iter')
print(iter)
print(paste('A',mean(abs(A - A_old))))
print(paste('v',mean(abs(v - v_old))))
print(paste('z',mean(abs(z -z_old))))
print(paste('g',mean(abs(g -g_old))))
print(paste('l',mean(abs(lambda_1 - lambda_1_old))))
print(paste('2',mean(abs(lambda_2 - lambda_2_old))))
print(paste('3',mean(abs(lambda_3 - lambda_3_old))))
}
# whether coverage
if(mean(abs(A - A_old)) < tol &
mean(abs(v - v_old)) < tol &
mean(abs(z - z_old)) < tol &
mean(abs(g - g_old)) < tol &
mean(abs(lambda_1 - lambda_1_old)) < tol &
mean(abs(lambda_2 - lambda_2_old)) < tol &
mean(abs(lambda_3 - lambda_3_old)) < tol ){
return(list(A = A,
v = v,
z = z,
g = g,
lambad_1 = lambda_1,
lambad_2 = lambda_2,
lambad_3 = lambda_3,
niter = iter))
break
}
}
if(iter == niter){
return(list(A = A,
v = v,
z = z,
g = g,
lambad_1 = lambda_1,
lambad_2 = lambda_2,
lambad_3 = lambda_3,
niter = iter))
}
}
set.seed(123)
X = data_gen(n = 100, true_p=40, p = 80)
# set parameters
nu1 = nu2 = nu3 = gamma_1 = gamma_2 = gamma_3 = 0.1
m = 5
phi = 0.5
# sparse.biADMM algorithm
res1 = sparse.biADMM(X, nu1, nu2, nu3, gamma_1, gamma_2, gamma_3, feature_weight = rep(1,ncol(X)),
m, phi, niter = 10, tol = 0.0001, output = 0)
cvxclustr::kernel_weights
sparse.biADMM = function(X, nu1, nu2, nu3,
gamma_1, gamma_2, gamma_3,
feature_weight = rep(1,ncol(X)),
m = 5, phi=0.5,niter = 1000,tol = 0.1,output = 1){
require(reticulate)
require(cvxbiclustr)
require(cvxclustr)
require(Matrix)
require(MASS)
n <- dim(X)[1]; p <- dim(X)[2]
n2 <- n*(n-1)/2
p2 <- p*(p-1)/2
elks <- elk(n,p)
el1 <- elks$el1
el2 <- elks$el2
ek1 <- elks$ek1
ek2 <- elks$ek2
k_row <- m
k_col <- m
w_row <- cvxclustr::kernel_weights(t(X), phi)
w_col <- cvxclustr::kernel_weights(X, phi)
w_row <- knn_weights(w_row, k_row, n)
w_col <- knn_weights(w_col, k_col, p)
w_row <- w_row/sum(w_row)
w_col <- w_col/sum(w_col)
w_row <- w_row/sqrt(p)
w_col <- w_col/sqrt(n)
feature_weight <- feature_weight/ sum(feature_weight)/sqrt(n)
# row and column weight
w_l <- w_row; u_k <- w_col
A <- matrix(0,n,p)
v <- matrix(0,p,n2)
z <- matrix(0,n,p2)
g <- matrix(0,n,p)
lambda_1 <- matrix(0,p,n2)
lambda_2 <- matrix(0,n,p2)
lambda_3 <- matrix(0,n,p)
for(iter in 1: niter){
A_old <- A; v_old <- v; z_old <- z; g_old <- g;
lambda_1_old <- lambda_1; lambda_2_old <- lambda_2 ; lambda_3_old <- lambda_3
# update A
# En <- diag(0:(n - 1)) + diag((n - 1):0) - matrix(1, n, n) + diag(1, n, n)
# Ep <- diag(0:(p - 1)) + diag((p - 1):0) - matrix(1, p, p) + diag(1, p, p)
En <- diag(n,n) - matrix(1, n, n)
Ep <- diag(p,p) - matrix(1, p, p)
M <- diag(1,n,n) + nu1 * En
N <- nu2 * Ep + nu3 * diag(1,p)
lv <- lambda_1 + nu1 * v
lz <- lambda_2 + nu2 * z
lg <- lambda_3 + nu3 * g
C2 <- (el1-el2) %*% t(lv)
C3 <- lz %*% t(ek1-ek2)
C4 <- lg %*% diag(1,p)
C <- X +  C2 + C3 + C4
A <- sylvester(M,t(N),C)
al1 <- t(A) %*% el1
al2 <- t(A) %*% el2
ak1 <- A %*% ek1
ak2 <- A %*% ek2
# update v z g
sigma_1 <- gamma_1 * w_l/nu1
vtemp <- al1 - al2 - 1/nu1 * lambda_1
# get positive results
temp1 <- ifelse((1 - sigma_1/sqrt(apply(vtemp^2,2,sum))) < 0, 0,1 - sigma_1/sqrt(apply(vtemp^2,2,sum)))
temp2 <- matrix(temp1,dim(vtemp)[1],dim(vtemp)[2], byrow = TRUE) * vtemp
v <- temp2
ztemp <- ak1 - ak2 - 1/nu2 * lambda_2
sigma_2 <- gamma_2 * u_k/nu2
temp3 <- ifelse((1 - sigma_2/sqrt(apply(ztemp^2,2,sum))) < 0, 0,1 - sigma_2/sqrt(apply(ztemp^2,2,sum)))
temp4 <- matrix(temp3,dim(ztemp)[1],dim(ztemp)[2], byrow = TRUE) * ztemp
z <- temp4
gtemp <- A - 1/nu3 * lambda_3
sigma_3 <- gamma_3 * feature_weight/nu3
temp5 <- ifelse((1 - sigma_3/sqrt(apply(gtemp^2,2,sum))) < 0, 0,1 - sigma_3/sqrt(apply(gtemp^2,2,sum)))
temp6 <- matrix(temp5,dim(gtemp)[1],dim(gtemp)[2], byrow = TRUE) * gtemp
g <- temp6
# update lambda 1
lambda_1 <- lambda_1 + nu1 * (v - al1 + al2)
# update lambda 2
lambda_2 <- lambda_2 + nu2 * (z - ak1 + ak2)
# update lambda 3
lambda_3 <- lambda_3 + nu3 * (g - A)
if(output == 1){
print('iter')
print(iter)
print(paste('A',mean(abs(A - A_old))))
print(paste('v',mean(abs(v - v_old))))
print(paste('z',mean(abs(z -z_old))))
print(paste('g',mean(abs(g -g_old))))
print(paste('l',mean(abs(lambda_1 - lambda_1_old))))
print(paste('2',mean(abs(lambda_2 - lambda_2_old))))
print(paste('3',mean(abs(lambda_3 - lambda_3_old))))
}
# whether coverage
if(mean(abs(A - A_old)) < tol &
mean(abs(v - v_old)) < tol &
mean(abs(z - z_old)) < tol &
mean(abs(g - g_old)) < tol &
mean(abs(lambda_1 - lambda_1_old)) < tol &
mean(abs(lambda_2 - lambda_2_old)) < tol &
mean(abs(lambda_3 - lambda_3_old)) < tol ){
return(list(A = A,
v = v,
z = z,
g = g,
lambad_1 = lambda_1,
lambad_2 = lambda_2,
lambad_3 = lambda_3,
niter = iter))
break
}
}
if(iter == niter){
return(list(A = A,
v = v,
z = z,
g = g,
lambad_1 = lambda_1,
lambad_2 = lambda_2,
lambad_3 = lambda_3,
niter = iter))
}
}
set.seed(123)
X = data_gen(n = 100, true_p=40, p = 80)
# set parameters
nu1 = nu2 = nu3 = gamma_1 = gamma_2 = gamma_3 = 0.1
m = 5
phi = 0.5
# sparse.biADMM algorithm
res1 = sparse.biADMM(X, nu1, nu2, nu3, gamma_1, gamma_2, gamma_3, feature_weight = rep(1,ncol(X)),
m, phi, niter = 10, tol = 0.0001, output = 0)
dim(res1$A)
knn_weights
devtools::document()
devtools::document()
devtools::document()
rm(list = c("sparse.biADMM", "sparse.biADMM.speed",
"sparse.biADMM.speed.WS"))
devtools::document()
devtools::document()
rm(list = c("biADMM"))
devtools::document()
devtools::build()
library("SpcvxBic")
#simulation for cobra and sparseBC
# 12/24/2023
pac <- c("survival","plyr","ggplot2","reshape2","phyloseq",'dirmult',"microbiome","vegan","e1071","caret","pROC",
"fossil","cvxclustr","cvxbiclustr","doParallel","foreach","mclust","Matrix","MASS","reticulate",'sparseBC')
.tmp <- lapply(pac, library, character.only = T)
setwd('C:/Users/matebook 14/Desktop/函数型数据聚类/我的论文内容/bicluster/Re_ sparse convex biclustering')
source("./R/data_gen.R")
source("./R/sylvester.R")
source("./R/SCB_ADMM.R")
source("./R/SCB_ADMM_speed.R")
source("./R/util.R")
source("./R/cluster assignment.R")
source('./R/prediction_validation_biclustering.R')
source('./R/bicluster.label.R')
source('./R/feature_selection_diagnostic.R')
source('./R/biADMM.R')
source("./R/SCB_ADMM_speed_WS.R")
# source("./R/kernal.knn.R")
# source('E:/Google Drive/Research/Convex Biclustering/simulation/all functions 04.2021.R')
# evaluate ARI of algo with mean and sd
MSD <- function(x) {
if (is.list(x)) {
x <- unlist(x)
}
mean_val <- round(mean(x),2)
sd_val <- round(sd(x),2)
paste("mean is", mean_val, ", sd is", sd_val)
}
res.list<- list()
nu1 = nu2 = nu3 = 1e+4 # 500
m = 5
phi = 1
tol = 5e-6
n = 500
p = 1000 # 200
true_p = 100 #10 is good may 15
theta = 1 # 1 is good
theta_noise = 3# 1 is good,2^(1/2) is great
row_group = 4 #行聚成几类
col_group = 4 #列聚成几类，col对应特征
mu.lower = -5#-3
mu.upper = 5#3
# repetition
rep.num = 50
cobra.adj.rand <-numeric()
cobra.validate.adj.rand <-numeric()
best.cobra.adj.rand<-numeric()
best.cobra.validate.adj.rand <-numeric()
bic.adj.rand <-numeric()
bic.validate.adj.rand <-numeric()
#### start simulations
for (ii in 1:rep.num){ # 重复50 次
cat('\n',ii,'time repeat start')
t0 <- Sys.time()
X = data_gen(seed.cluster = 123*ii, seed.data = 654*ii, n=n, true_p=true_p, p=p,
mu.lower=mu.lower, mu.upper=mu.upper,
theta = theta, theta_noise=theta_noise, row_group = row_group, col_group = col_group)
scale.X <- X
norm.X.f <- norm(scale.X,'f')
scale.X <- scale.X/norm.X.f
# generate a validation data given the same clustering structure
val.X <- data_gen(seed.cluster = 123*ii, seed.data = 654*3*ii, n=n, true_p=true_p, p=p,
mu.lower=mu.lower, mu.upper=mu.upper,
theta = theta, theta_noise=theta_noise, row_group = row_group, col_group = col_group)
scale.val.X <- val.X
norm.scale.X.f <- norm(scale.val.X,'f')
scale.val.X <- scale.val.X/norm.scale.X.f
# create cluster labels by row and columns
bi.X.groups = bicluster.label(scale.X)
bi.val.X.groups = bicluster.label(scale.val.X)
#############################################################cobra copy code for 'Bicluster via sparse cluster'
nGamma <- 10
phi <- 0.5; k <- 10
Convex.start <- Sys.time()
wts <- gkn_weights(scale.X,phi=phi,k_row=k,k_col=k)
w_row <- wts$w_row; w_col <- wts$w_col; E_row <- wts$E_row; E_col <- wts$E_col
gammaSeq<-seq(1,100,nGamma)
sol <- cobra_validate(scale.X,E_row,E_col,w_row,w_col,gammaSeq,fraction=0.1)
cobra.adj.rand <-numeric()
cobra.validate.adj.rand <-numeric()
for (i in 1:nGamma){
print (i)
cobra.dat = scale.X
if(length(sol[["groups_row"]][[i]]$size)*length(sol[["groups_col"]][[i]]$cluster) >10000){
next}
rownames(cobra.dat) = sol[["groups_row"]][[i]]$cluster
colnames(cobra.dat) = sol[["groups_col"]][[i]]$cluster
cobra.X.groups = bicluster.label(cobra.dat)
cobra.adj.rand[i] = adjustedRandIndex(cobra.X.groups$num, bi.X.groups$num)
cobra.validate = predict_bi_validate(scale.X,sol[["groups_row"]][[i]]$cluster,sol[["groups_col"]][[i]]$cluster,
scale.val.X, bi.val.X.groups$num)
cobra.validate.adj.rand[i] = cobra.validate$adj.rand
}
cobra.adj.rand[is.na(cobra.adj.rand)] <- 0
cobra.validate.adj.rand[is.na(cobra.validate.adj.rand)] <- 0
best.cobra.adj.rand[ii] <-ifelse(length(cobra.validate.adj.rand) == 0, 0, max(cobra.adj.rand))
best.cobra.validate.adj.rand[ii] <-ifelse(length(cobra.adj.rand) == 0, 0, max(cobra.adj.rand))
####################################################### sparseBC
lambda<-sparseBC.BIC(scale.X,k=4,r=4,lambda=seq(0,100,10))$lambda
res.bic <-sparseBC(scale.X,4,5,lambda)
bic.dat = scale.X
rownames(bic.dat) = res.bic$Cs
colnames(bic.dat) = res.bic$Ds
bic.X.groups = bicluster.label(bic.dat)
bic.adj.rand[ii] = adjustedRandIndex(bic.X.groups$num, bi.X.groups$num)
bic.validate = predict_bi_validate(scale.X,res.bic$Cs,res.bic$Ds,
scale.val.X, bi.val.X.groups$num)
bic.validate.adj.rand[ii] = bic.validate$adj.rand
cat('\n',ii,'time repeat finished')
print(data.frame(mean(best.cobra.adj.rand),sd(best.cobra.adj.rand),
mean(best.cobra.validate.adj.rand),sd(best.cobra.validate.adj.rand),
mean(bic.adj.rand),sd(bic.adj.rand),
mean(bic.validate.adj.rand),sd(bic.validate.adj.rand) ))
}
library(devtools)
install_github("jsshanmai/SpcvxBic")
file.edit('DESCRIPTION')
file.edit('DESCRIPTION')
library(reticulate)
py_config()
?source_python
?eval
devtools::document()
?cluster
library(cluster)
library(1)
devtools::document()
devtools::document()
library(cvxbiclustr)
install.packages('cvxbiclustr')
library(cvxbiclustr)
library(cvxbiclustr)
library(cvxbiclustr)
install.packages('cvxbiclustr')
install.packages("cvxbiclustr")
install.packages("C:/Users/matebook 14/Desktop/cvxbiclustr_0.0.1.tar.gz", repos = NULL, type = "source")
library(cvxbiclustr)
biADMM.speed = function(X, nu1,nu2, gamma_1, gamma_2, m,
phi,  prox = 'l2', niters = 10, tol = 0.1, output = 1){
require(reticulate)
#require(cvxbiclustr)
require(cvxclustr)
require(Matrix)
require(MASS)
# path <- paste(system.file(package="biclusADMM"), "biADMM_python.py", sep="/")
source_python(path)
n <- dim(X)[1]
p <- dim(X)[2]
k_row <- m; k_col <- m
w_row <- kernel_weights(t(X), phi)
w_col <- kernel_weights(X, phi)
w_row <- knn_weights(w_row, k_row, n)
w_col <- knn_weights(w_col, k_col, p)
w_row <- w_row/sum(w_row)
w_col <- w_col/sum(w_col)
w_row <- w_row/sqrt(p)
w_col <- w_col/sqrt(n)
w_l <- w_row
u_k <- w_col
w_l <- matrix(w_l, length(w_l),1)
u_k <- matrix(u_k, length(u_k),1)
res <- biADMM_python(X, nu1, nu2, gamma_1, gamma_2,
w_l, u_k,
prox,
niters, tol, output = output)
result <- list(A = res[[1]], v = res[[2]], z = res[[3]],
lambda_1 = res[[4]], lambda_2 = res[[5]], iters = res[[6]])
return(result)
}
set.seed(123)
X = data_gen(n = 100, p = 80)
devtools::document()
library(devtools)
install.packages("devtools")
library(devtools)
library(devtools)
devtools::document()
library(biADMM)
install_github("sakuramomo1005/biADMM")
library(biADMM)
devtools::document()
install.packages('cvxclustr')
install_github("echi/cvxclustr")
cvxclustr
install.packages("cvxclustr")
install.packages("C:/Users/matebook 14/Desktop/cvxclustr_1.1.1.tar.gz", repos = NULL, type = "source")
library(devtools)
devtools:document()
?sparse.biADMM.speed.WS
data_gen
?data_gen
devtools::document()
library(devtools)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
requireNamespace("caret")
devtools::document()
getOptions('devtools.desc.license')
devtools::document()
requireNamespace(stats)
library(stats)
requireNamespace("caret")
requireNamespace("stats")
requireNamespace("reticulate")
devtools::document()
